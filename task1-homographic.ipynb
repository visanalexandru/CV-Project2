{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b40ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video import *\n",
    "import numpy as np\n",
    "import ultralytics\n",
    "import cv2 as cv\n",
    "from utils import *\n",
    "from tqdm import tqdm \n",
    "from ultralytics import RTDETR\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a36d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamental_matrices = {\n",
    "    \"A\" : {\n",
    "        \"B\": np.load(\"fundamental_matrices/AB.npy\"),\n",
    "        \"C\": np.load(\"fundamental_matrices/AC.npy\"),\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"A\": np.load(\"fundamental_matrices/BA.npy\"),\n",
    "        \"C\": np.load(\"fundamental_matrices/BC.npy\"),\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"B\": np.load(\"fundamental_matrices/CB.npy\"),\n",
    "        \"A\": np.load(\"fundamental_matrices/CA.npy\"),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78bb589",
   "metadata": {},
   "outputs": [],
   "source": [
    "homography_matrices = {\n",
    "    \"A\" : {\n",
    "        \"B\": np.load(\"homography_matrices/AB.npy\"),\n",
    "        \"C\": np.load(\"homography_matrices/AC.npy\"),\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"A\": np.load(\"homography_matrices/BA.npy\"),\n",
    "        \"C\": np.load(\"homography_matrices/BC.npy\"),\n",
    "    },\n",
    "    \"C\": {\n",
    "        \"B\": np.load(\"homography_matrices/CB.npy\"),\n",
    "        \"A\": np.load(\"homography_matrices/CA.npy\"),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = YOLO(\"yolov9e.pt\")\n",
    "#model.track(\"train/task1/02_query.mp4\", show=True, tracker=\"./trackers/bytetrack.yaml\", conf=0.1, iou=0.1, agnostic_nms=True, augment=True, max_det=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fee147",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'query' in globals():\n",
    "    del query\n",
    "if 'reference' in globals():\n",
    "    del reference\n",
    "\n",
    "query = load_video(\"train/task1/01_query.mp4\")\n",
    "reference = load_video(\"train/task1/01_reference.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731365ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.do_tracking()\n",
    "reference.do_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_query = query.get_camera()\n",
    "camera_reference = reference.get_camera()\n",
    "\n",
    "print(\"Query camera:\", camera_query)\n",
    "print(\"Reference camera:\", camera_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ee0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = fundamental_matrices[camera_query][camera_reference] \n",
    "print(F)\n",
    "F_inv = fundamental_matrices[camera_reference][camera_query] \n",
    "print(F_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47003911",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = homography_matrices[camera_query][camera_reference]\n",
    "print(H)\n",
    "H_inv = homography_matrices[camera_reference][camera_query]\n",
    "print(H_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08915b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_index = 0 \n",
    "reference_index = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c60bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Removes those points that would be outside the frame when transformed to the other camera's frame.\n",
    "def filter_points_homography(points, H):\n",
    "    transformed_points = cv.perspectiveTransform(points.reshape(-1, 1, 2).astype(np.float32), H).squeeze()\n",
    "\n",
    "    in_bounds = np.logical_and(\n",
    "        np.logical_and(transformed_points[:, 0] >= 0, transformed_points[:, 0] < FRAME_WIDTH),\n",
    "        np.logical_and(transformed_points[:, 1] >= 0, transformed_points[:, 1] < FRAME_HEIGHT)\n",
    "    )\n",
    "\n",
    "    return points[in_bounds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6803b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_epipolar(query, reference, visualize=False):\n",
    "    moving_pixels_query = query.moving_pixels()\n",
    "    moving_pixels_reference = reference.moving_pixels()\n",
    "\n",
    "    # Get the actual coordinates of the moving pixels\n",
    "    rows, cols = np.where(moving_pixels_query)\n",
    "    points_query = np.stack((cols, rows), axis=1) \n",
    "\n",
    "    rows, cols = np.where(moving_pixels_reference)\n",
    "    points_reference = np.stack((cols, rows), axis=1) \n",
    "\n",
    "    if len(points_query) == 0 or len(points_reference) == 0:\n",
    "        return None\n",
    "\n",
    "    # Filter points that would be outside the frame when transformed to the other camera's frame.\n",
    "    points_query = filter_points_homography(points_query, H)\n",
    "    points_reference = filter_points_homography(points_reference, H_inv)\n",
    "\n",
    "    if len(points_query) == 0 or len(points_reference) == 0:\n",
    "        return None\n",
    "\n",
    "    # Downsample points to avoid too many points\n",
    "    if len(points_query) > 10000:\n",
    "        indices = np.random.choice(len(points_query), 10000, replace=False)\n",
    "        points_query = points_query[indices]\n",
    "\n",
    "    if len(points_reference) > 10000:\n",
    "        indices = np.random.choice(len(points_reference), 10000, replace=False)\n",
    "        points_reference = points_reference[indices]\n",
    "\n",
    "    # Compute the epipolar lines for the query points in the reference frame.\n",
    "    transformed = cv.perspectiveTransform(points_query.reshape(-1, 1, 2).astype(np.float32), H).squeeze()\n",
    "    score = 0\n",
    "\n",
    "    # Just prepare the plots if visualization is enabled.\n",
    "    if visualize:\n",
    "        query_plot = query.raw().copy()\n",
    "        reference_plot = reference.raw().copy()\n",
    "\n",
    "    chosen = np.zeros(len(points_reference), dtype=bool)\n",
    "    for i, point in enumerate(transformed):\n",
    "        points_to_check = points_reference[~chosen]\n",
    "        distances = np.linalg.norm(points_to_check - point, axis=1)\n",
    "\n",
    "        minimum_index = np.argmin(distances)\n",
    "        minimum_distance = distances[minimum_index]\n",
    "\n",
    "        if minimum_distance < 20:\n",
    "            score+=1\n",
    "\n",
    "            # Mark this point as chosen so we don't use it again.\n",
    "            chosen[minimum_index] = True\n",
    "\n",
    "            if visualize:\n",
    "                color = np.random.randint(0, 255, size=3).tolist()\n",
    "                cv.circle(query_plot, (points_query[i][0], points_query[i][1]), 10, color, -1)\n",
    "                close_point = points_reference[minimum_index]\n",
    "                cv.circle(reference_plot, (close_point[0], close_point[1]), 10, color, -1)\n",
    "    \n",
    "    if visualize:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(20, 30))\n",
    "        axs[0].imshow(moving_pixels_query)\n",
    "        axs[1].imshow(moving_pixels_reference)\n",
    "        plt.show()\n",
    "        \n",
    "        fig, axs = plt.subplots(1, 2, figsize=(20, 30))\n",
    "        axs[0].imshow(query_plot)\n",
    "        axs[0].set_title(\"Query Frame\")\n",
    "        axs[0].axis('off')\n",
    "        axs[1].imshow(reference_plot)\n",
    "        axs[1].set_title(\"Reference Frame\")\n",
    "        axs[1].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score = similarity_epipolar(query.get_frame(query_index), reference.get_frame(reference_index), \n",
    "                              visualize=True)\n",
    "print(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d6fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_score(reference_start_index):\n",
    "    num_query_frames = query.num_frames()\n",
    "    score = 0\n",
    "    for t in range(0, num_query_frames, 10):\n",
    "        query_frame = query.get_frame(t)\n",
    "        reference_frame = reference.get_frame(reference_start_index + t)\n",
    "\n",
    "        cost = similarity_epipolar(query_frame, reference_frame)\n",
    "        if cost is not None:\n",
    "            score += cost\n",
    "\n",
    "    return (reference_start_index, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73981ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_query_frames = query.num_frames()\n",
    "num_reference_frames = reference.num_frames()\n",
    "print(num_query_frames)\n",
    "costs = []\n",
    "\n",
    "with Pool() as pool:\n",
    "    starts = range(0, num_reference_frames-num_query_frames+1, 10)\n",
    "    results = list(tqdm(pool.imap(overlap_score, starts), total=len(starts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "plt.plot([result[0] for result in results], [result[1] for result in results])\n",
    "\n",
    "argmax = np.argmax([result[1] for result in results])\n",
    "print(results[argmax])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
